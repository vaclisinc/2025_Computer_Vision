<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project 5: Diffusion Models (Parts A & B)</title>
    <link rel="stylesheet" href="css/styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Space+Grotesk:wght@400;500;600;700&family=JetBrains+Mono&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
</head>
<body>
    <div class="page">
        <header>
            <div class="header-gradient"></div>
            <div class="header-shell">
                <a class="back-link" href="../index.html">← Back to Projects</a>
                <div class="header-main">
                    <div>
                        <h1>Project 5 · Diffusion & Flow Models</h1>
                        <p class="subtitle">CS 180 / 280A · Song-Ze Yu · Seed = 100</p>
                    </div>
                    <div class="status-tags">
                        <span class="tag">Part A · DeepFloyd IF</span>
                        <span class="tag">Part B · Flow Matching</span>
                        <span class="tag alt">Fall 2025</span>
                    </div>
                </div>

            </div>
        </header>

        <nav class="toc">
            <a href="#parta">Part A</a>
            <a href="#partb">Part B</a>
        </nav>

        <main>
            <section class="part-intro" id="parta">
                <div class="section-heading">
                    <span class="section-label">Part A</span>
                    <div>
                        <h2>DeepFloyd IF Diffusion</h2>
                    </div>
                </div>

                <!-- Part 0 -->
                <div class="task-cluster">
                    <div class="cluster-heading">
                        <span class="task-label">Part 0</span>
                        <h3>Setup & Prompts</h3>
                    </div>
                    <p>Generated text embeddings using DeepFloyd IF cluster on Hugging Face. Seed=100.</p>

                    <h4>All Prompts Designed:</h4>
                    <ul class="mini-list">
                        <li>'a picture of canyon'</li>
                        <li>'a picture of a finger'</li>
                        <li>'a lonely robot waiting for a bus in the snow'</li>
                        <li>'a painting of a piano'</li>
                        <li>'a painting of a zebra'</li>
                        <li>'a cat and a dog merged into one animal'</li>
                        <li>'a guitar that transforms into a bird while being played'</li>
                        <li>'half human half tree standing in a baseball stadium'</li>
                        <li>'Shohei Ohtani eating his baseball'</li>
                        <li>'a cyberpunk city reflected on water, pixel art style'</li>
                        <li>'a rainy street at night with only one yellow light on and a store opened'</li>
                        <li>'a moon and stars and a couple kissing and becomes two monkeys'</li>
                        <li>'a high quality photo'</li>
                        <li>'' (empty prompt)</li>
                    </ul>

                    <h4 style="margin-top: 1.5rem;">Selected 3 Prompts with num_inference_steps=20:</h4>
                    <div class="media-row">
                        <figure>
                            <img src="src/img/parta_cell16_out3_img0.png" alt="Robot in snow" />
                            <figcaption>"a lonely robot waiting for a bus in the snow"</figcaption>
                        </figure>
                        <figure>
                            <img src="src/img/parta_cell16_out3_img1.png" alt="Human-tree hybrid" />
                            <figcaption>"half human half tree standing in a baseball stadium"</figcaption>
                        </figure>
                        <figure>
                            <img src="src/img/parta_cell16_out3_img2.png" alt="Cyberpunk city" />
                            <figcaption>"a cyberpunk city reflected on water, pixel art style"</figcaption>
                        </figure>
                    </div>

                    <h4 style="margin-top: 1.5rem;">Same Prompts with num_inference_steps=200:</h4>
                    <div class="media-row">
                        <figure>
                            <img src="src/img/messageImage_1765781023123_0.jpg" alt="Robot in snow (200 steps)" />
                            <figcaption>"a lonely robot waiting for a bus in the snow"</figcaption>
                        </figure>
                        <figure>
                            <img src="src/img/messageImage_1765781027863_0.jpg" alt="Human-tree hybrid (200 steps)" />
                            <figcaption>"half human half tree standing in a baseball stadium"</figcaption>
                        </figure>
                        <figure>
                            <img src="src/img/messageImage_1765781034413_0.jpg" alt="Cyberpunk city (200 steps)" />
                            <figcaption>"a cyberpunk city reflected on water, pixel art style"</figcaption>
                        </figure>
                    </div>
                </div>
            </section>

            <!-- Part 1 starts here -->

            <section class="task-cluster" id="part1-1">
                <div class="cluster-heading">
                    <span class="task-label">1.1</span>
                    <h3>Forward Process</h3>
                </div>
                <p>x_t = √(ᾱ_t)·x_0 + √(1-ᾱ_t)·ε. Applied to Campanile at t=[250, 500, 750].</p>
                <p><strong>Implementation:</strong> Add noise using the formula where epsilon is Gaussian noise from torch.randn_like(). The alphas_cumprod array contains cumulative product values that control scaling of the original image and noise at each timestep t.</p>
                <div class="media-row">
                    <figure>
                        <img src="src/img/1-1-campanile.jpg" alt="Original Campanile" />
                        <figcaption>Original Campanile</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_1.1_Implementing_the_forward_process_cell23_out1_img0.png" alt="Noisy t=250" />
                        <figcaption>Noisy t=250</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_1.1_Implementing_the_forward_process_cell23_out3_img0.png" alt="Noisy t=500" />
                        <figcaption>Noisy t=500</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_1.1_Implementing_the_forward_process_cell23_out5_img0.png" alt="Noisy t=750" />
                        <figcaption>Noisy t=750</figcaption>
                    </figure>
                </div>
            </section>

            <section class="task-cluster" id="part1-2">
                <div class="cluster-heading">
                    <span class="task-label">1.2</span>
                    <h3>Classical Denoising</h3>
                </div>
                <p>Gaussian blur on noisy images. Removes high-freq noise but can't reconstruct edges.</p>
                <p><strong>Implementation:</strong> Uses torchvision.transforms.functional.gaussian_blur with varying kernel sizes. The Gaussian blur is applied directly to noisy images, but results show it's not effective for high noise levels.</p>
                <div class="media-row">
                    <figure>
                        <img src="src/img/parta_1.2_Classical_Denoising_cell25_out1_img0.png" alt="t=250 noisy" />
                        <figcaption>t=250 Noisy</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_1.2_Classical_Denoising_cell25_out5_img0.png" alt="t=500 noisy" />
                        <figcaption>t=500 Noisy</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_1.2_Classical_Denoising_cell25_out9_img0.png" alt="t=750 noisy" />
                        <figcaption>t=750 Noisy</figcaption>
                    </figure>
                </div>
                <div class="media-row">
                    <figure>
                        <img src="src/img/parta_1.2_Classical_Denoising_cell25_out3_img0.png" alt="t=250 Gaussian denoised" />
                        <figcaption>t=250 Gaussian denoised</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_1.2_Classical_Denoising_cell25_out7_img0.png" alt="t=500 Gaussian denoised" />
                        <figcaption>t=500 Gaussian denoised</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_1.2_Classical_Denoising_cell25_out11_img0.png" alt="t=750 Gaussian denoised" />
                        <figcaption>t=750 Gaussian denoised</figcaption>
                    </figure>
                </div>
            </section>

            <section class="task-cluster" id="part1-3">
                <div class="cluster-heading">
                    <span class="task-label">1.3</span>
                    <h3>One-Step Denoising</h3>
                </div>
                <p>UNet predicts noise, recover x_0. Works for t≤500, struggles at t=750.</p>
                <p><strong>Implementation:</strong> Pass noisy image through stage_1.unet() to get noise estimate. Recover x_0 using x_0 = (x_t - √(1-ᾱ_t)·noise_pred) / √(ᾱ_t).</p>
                <div class="media-row">
                    <figure>
                        <img src="src/img/parta_cell27_out3_img0.png" alt="t=250 noisy" />
                        <figcaption>Noisy t=250</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_cell27_out9_img0.png" alt="t=500 noisy" />
                        <figcaption>Noisy t=500</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_cell27_out15_img0.png" alt="t=750 noisy" />
                        <figcaption>Noisy t=750</figcaption>
                    </figure>
                </div>
                <div class="media-row">
                    <figure>
                        <img src="src/img/parta_cell27_out5_img0.png" alt="One-step denoised t=250" />
                        <figcaption>One-step denoised (t=250)</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_cell27_out11_img0.png" alt="One-step denoised t=500" />
                        <figcaption>One-step denoised (t=500)</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_cell27_out17_img0.png" alt="One-step denoised t=750" />
                        <figcaption>One-step denoised (t=750)</figcaption>
                    </figure>
                </div>
            </section>

            <section class="task-cluster" id="part1-4">
                <div class="cluster-heading">
                    <span class="task-label">1.4</span>
                    <h3>Iterative Denoising</h3>
                </div>
                <p>DDPM sampling: t=990→0, stride=30. Iterative recovery from heavy noise.</p>
                <p><strong>Implementation:</strong> Loop from high timesteps to low (t=990 down to 0 with stride 30). At each step, predict noise and compute x_{t-1} from x_t using DDPM backward formula with optional random noise z.</p>
                <div class="media-row" style="grid-template-columns: repeat(5, 1fr);">
                    <figure>
                        <img src="src/img/parta_cell33_out0_img0.png" alt="Original" />
                        <figcaption>Original</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_cell33_out0_img1.png" alt="Noisy (t=690)" />
                        <figcaption>Noisy (t=690)</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_cell33_out0_img2.png" alt="Iterative Denoise" />
                        <figcaption>Iterative Denoise</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_cell33_out0_img3.png" alt="One-step Denoise" />
                        <figcaption>One-step Denoise</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_cell33_out0_img4.png" alt="Gaussian Blur" />
                        <figcaption>Gaussian Blur</figcaption>
                    </figure>
                </div>
            </section>

            <section class="task-cluster" id="part1-5">
                <div class="cluster-heading">
                    <span class="task-label">1.5</span>
                    <h3>Sampling</h3>
                </div>
                <p>Generate from pure noise. Prompt: "a high quality photo"</p>
                <p><strong>Implementation:</strong> Start with pure Gaussian noise torch.randn(), then run the iterative denoising loop from t=max down to t=0 to generate images from scratch.</p>
                <div class="media-row">
                    <figure><img src="src/img/parta_1.5_Diffusion_Model_Sampling_cell35_out1_img0.png" alt="Sample 1" /><figcaption>Sample 1</figcaption></figure>
                    <figure><img src="src/img/parta_1.5_Diffusion_Model_Sampling_cell35_out3_img0.png" alt="Sample 2" /><figcaption>Sample 2</figcaption></figure>
                    <figure><img src="src/img/parta_1.5_Diffusion_Model_Sampling_cell35_out5_img0.png" alt="Sample 3" /><figcaption>Sample 3</figcaption></figure>
                    <figure><img src="src/img/parta_1.5_Diffusion_Model_Sampling_cell35_out7_img0.png" alt="Sample 4" /><figcaption>Sample 4</figcaption></figure>
                    <figure><img src="src/img/parta_1.5_Diffusion_Model_Sampling_cell35_out9_img0.png" alt="Sample 5" /><figcaption>Sample 5</figcaption></figure>
                </div>
            </section>

            <section class="task-cluster" id="part1-6">
                <div class="cluster-heading">
                    <span class="task-label">1.6</span>
                    <h3>CFG</h3>
                </div>
                <p>ε = ε_uncond + γ·(ε_cond - ε_uncond), γ=7. Much sharper results!</p>
                <p><strong>Implementation:</strong> At each timestep, run UNet twice: once with prompt embeddings (conditional) and once with empty prompt (unconditional). Combine predictions using ε = ε_uncond + γ·(ε_cond - ε_uncond).</p>
                <div class="media-row">
                    <figure><img src="src/img/parta_1.6_Classifier_Free_Guidance_cell38_out2_img0.png" alt="CFG sample 1" /><figcaption>CFG sample 1</figcaption></figure>
                    <figure><img src="src/img/parta_1.6_Classifier_Free_Guidance_cell38_out4_img0.png" alt="CFG sample 2" /><figcaption>CFG sample 2</figcaption></figure>
                    <figure><img src="src/img/parta_1.6_Classifier_Free_Guidance_cell38_out6_img0.png" alt="CFG sample 3" /><figcaption>CFG sample 3</figcaption></figure>
                    <figure><img src="src/img/parta_1.6_Classifier_Free_Guidance_cell38_out8_img0.png" alt="CFG sample 4" /><figcaption>CFG sample 4</figcaption></figure>
                    <figure><img src="src/img/parta_1.6_Classifier_Free_Guidance_cell38_out10_img0.png" alt="CFG sample 5" /><figcaption>CFG sample 5</figcaption></figure>
                </div>
            </section>

            <section class="task-cluster" id="part1-7">
                <div class="cluster-heading">
                    <span class="task-label">1.7</span>
                    <h3>Image-to-Image</h3>
                </div>
                <p>SDEdit: partial noise + denoise</p>
                <p><strong>Implementation:</strong> Add noise to input image up to timestep i_start, then run denoising loop from i_start back to 0. Higher i_start = more noise = more variation from original.</p>

                <h4 style="margin: 1rem 0 0.5rem;">SDEdit with i_start = 1, 3, 5, 7, 10, 20</h4>
                <div class="media-row" style="grid-template-columns: repeat(6, 1fr);">
                    <figure>
                        <img src="src/img/parta_cell40_out1_img0.png" alt="i_start=1" />
                        <figcaption>i_start=1</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_cell40_out1_img1.png" alt="i_start=3" />
                        <figcaption>i_start=3</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_cell40_out1_img2.png" alt="i_start=5" />
                        <figcaption>i_start=5</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_cell40_out1_img3.png" alt="i_start=7" />
                        <figcaption>i_start=7</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_cell40_out1_img4.png" alt="i_start=10" />
                        <figcaption>i_start=10</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_cell40_out1_img5.png" alt="i_start=20" />
                        <figcaption>i_start=20</figcaption>
                    </figure>
                </div>

                <div class="accordion" style="margin-top: 2rem;">
                    <details>
                    <summary>1.7.1 Hand-Drawn Edits</summary>
                        <p><strong>Staff-provided avocado chair:</strong></p>
                        <div class="media-row" style="grid-template-columns: repeat(6, 1fr);">
                            <figure>
                                <img src="src/img/parta_cell44_out1_img0.png" alt="i_start=1" />
                                <figcaption>i_start=1</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell44_out1_img1.png" alt="i_start=3" />
                                <figcaption>i_start=3</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell44_out1_img2.png" alt="i_start=5" />
                                <figcaption>i_start=5</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell44_out1_img3.png" alt="i_start=7" />
                                <figcaption>i_start=7</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell44_out1_img4.png" alt="i_start=10" />
                                <figcaption>i_start=10</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell44_out1_img5.png" alt="i_start=20" />
                                <figcaption>i_start=20</figcaption>
                            </figure>
                        </div>

                        <p style="margin-top: 2rem;"><strong>Custom hand-drawn images from Instagram stories: sheep, bear, stick figure, snoopy</strong></p>

                        <h5 style="margin-top: 1rem;">Sheep:</h5>
                        <div class="media-row" style="grid-template-columns: repeat(6, 1fr);">
                            <figure>
                                <img src="src/img/parta_cell49_out1_img0.png" alt="Sheep i_start=1" />
                                <figcaption>i_start=1</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell49_out1_img1.png" alt="Sheep i_start=3" />
                                <figcaption>i_start=3</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell49_out1_img2.png" alt="Sheep i_start=5" />
                                <figcaption>i_start=5</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell49_out1_img3.png" alt="Sheep i_start=7" />
                                <figcaption>i_start=7</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell49_out1_img4.png" alt="Sheep i_start=10" />
                                <figcaption>i_start=10</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell49_out1_img5.png" alt="Sheep i_start=20" />
                                <figcaption>i_start=20</figcaption>
                            </figure>
                        </div>

                        <h5 style="margin-top: 1rem;">Bear:</h5>
                        <div class="media-row" style="grid-template-columns: repeat(6, 1fr);">
                            <figure>
                                <img src="src/img/parta_cell47_out1_img0.png" alt="Bear i_start=1" />
                                <figcaption>i_start=1</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell47_out1_img1.png" alt="Bear i_start=3" />
                                <figcaption>i_start=3</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell47_out1_img2.png" alt="Bear i_start=5" />
                                <figcaption>i_start=5</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell47_out1_img3.png" alt="Bear i_start=7" />
                                <figcaption>i_start=7</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell47_out1_img4.png" alt="Bear i_start=10" />
                                <figcaption>i_start=10</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell47_out1_img5.png" alt="Bear i_start=20" />
                                <figcaption>i_start=20</figcaption>
                            </figure>
                        </div>

                        <h5 style="margin-top: 1rem;">Stick Figure:</h5>
                        <div class="media-row" style="grid-template-columns: repeat(6, 1fr);">
                            <figure>
                                <img src="src/img/parta_cell48_out1_img0.png" alt="Stick i_start=1" />
                                <figcaption>i_start=1</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell48_out1_img1.png" alt="Stick i_start=3" />
                                <figcaption>i_start=3</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell48_out1_img2.png" alt="Stick i_start=5" />
                                <figcaption>i_start=5</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell48_out1_img3.png" alt="Stick i_start=7" />
                                <figcaption>i_start=7</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell48_out1_img4.png" alt="Stick i_start=10" />
                                <figcaption>i_start=10</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell48_out1_img5.png" alt="Stick i_start=20" />
                                <figcaption>i_start=20</figcaption>
                            </figure>
                        </div>

                        <h5 style="margin-top: 1rem;">Snoopy:</h5>
                        <div class="media-row" style="grid-template-columns: repeat(6, 1fr);">
                            <figure>
                                <img src="src/img/parta_cell50_out1_img0.png" alt="Snoopy i_start=1" />
                                <figcaption>i_start=1</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell50_out1_img1.png" alt="Snoopy i_start=3" />
                                <figcaption>i_start=3</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell50_out1_img2.png" alt="Snoopy i_start=5" />
                                <figcaption>i_start=5</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell50_out1_img3.png" alt="Snoopy i_start=7" />
                                <figcaption>i_start=7</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell50_out1_img4.png" alt="Snoopy i_start=10" />
                                <figcaption>i_start=10</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell50_out1_img5.png" alt="Snoopy i_start=20" />
                                <figcaption>i_start=20</figcaption>
                            </figure>
                        </div>
                    </details>
                    <details id="part1-7-2">
                        <summary>1.7.2 Inpainting</summary>
                        <p>Fill masked regions. At each step: denoise, then re-impose unmasked pixels.</p>
                        <p><strong>Implementation:</strong> During denoising loop, after each UNet prediction, replace unmasked regions with original noisy values at that timestep. Masked regions are filled by the model.</p>
                        <div class="media-row">
                            <figure>
                                <img src="src/img/parta_cell54_out0_img0.png" alt="Original" />
                                <figcaption>Original</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell54_out0_img1.png" alt="Mask" />
                                <figcaption>Mask</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell54_out0_img2.png" alt="Inpainted" />
                                <figcaption>Inpainted</figcaption>
                            </figure>
                        </div>
                    </details>
                    <details id="part1-7-3">
                        <summary>1.7.3 Text-Conditional Image-to-Image</summary>
                        <p>Prompt: "a lonely robot waiting for a bus in the snow". i_start = [1, 3, 5, 7, 10, 20]</p>
                        <p><strong>Implementation:</strong> Same as SDEdit but uses different prompt embeddings during denoising. The prompt guides the transformation while preserving structure from original image.</p>
                        <div class="media-row" style="grid-template-columns: repeat(6, 1fr);">
                            <figure>
                                <img src="src/img/parta_cell56_out1_img0.png" alt="i_start=1" />
                                <figcaption>i_start=1</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell56_out1_img1.png" alt="i_start=3" />
                                <figcaption>i_start=3</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell56_out1_img2.png" alt="i_start=5" />
                                <figcaption>i_start=5</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell56_out1_img3.png" alt="i_start=7" />
                                <figcaption>i_start=7</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell56_out1_img4.png" alt="i_start=10" />
                                <figcaption>i_start=10</figcaption>
                            </figure>
                            <figure>
                                <img src="src/img/parta_cell56_out1_img5.png" alt="i_start=20" />
                                <figcaption>i_start=20</figcaption>
                            </figure>
                        </div>
                    </details>
                </div>
            </section>

            <section class="task-cluster" id="part1-8">
                <div class="cluster-heading">
                    <span class="task-label">1.8</span>
                    <h3>Visual Anagrams</h3>
                </div>
                <p>Dual-prompt noise averaging. The image looks different when flipped upside down!</p>
                <p><strong>Implementation:</strong> At each timestep, predict noise with prompt1 normally, then flip image 180°, predict noise with prompt2, flip back. Average the two noise predictions: ε = (ε1 + ε2_flipped) / 2.</p>
                <div class="media-row">
                    <figure>
                        <img src="src/img/parta_1.8_Visual_Anagrams_cell59_out0_img0.png" alt="Visual anagram upright" />
                        <figcaption>Upright: "a lonely robot waiting for a bus in the snow"</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_1.8_Visual_Anagrams_cell59_out0_img1.png" alt="Visual anagram flipped" />
                        <figcaption>Flipped: "a cyberpunk city reflected on water, pixel art style"</figcaption>
                    </figure>
                </div>
            </section>

            <section class="task-cluster" id="part1-9">
                <div class="cluster-heading">
                    <span class="task-label">1.9</span>
                    <h3>Hybrid Images</h3>
                </div>
                <p>Factorized diffusion with Gaussian blur (kernel=33, σ=2)</p>
                <p><strong>Implementation:</strong> Predict noise with prompt_low, apply Gaussian blur to get low-freq component. Predict noise with prompt_high on (original - blurred) to get high-freq. Combine: ε = ε_low_blur + ε_high_residual.</p>
                <div class="media-row">
                    <figure>
                        <img src="src/img/parta_1.9_Hybrid_Images_cell62_out0_img0.png" alt="Hybrid image 1" />
                        <figcaption>Low-freq: "a picture of a finger" / High-freq: "a picture of canyon"</figcaption>
                    </figure>
                    <figure>
                        <img src="src/img/parta_1.9_Hybrid_Images_cell63_out0_img0.png" alt="Hybrid image 2" />
                        <figcaption>Low-freq: "a painting of a piano" / High-freq: "a painting of a zebra"</figcaption>
                    </figure>
                </div>
            </section>

            <section class="part-intro" id="partb">
                <div class="section-heading">
                    <span class="section-label">Part B</span>
                    <div>
                        <h2>Flow Matching from Scratch</h2>
                        <p>Train UNet on MNIST: single-step denoiser → time-conditioned flow matching → class-conditioned generation with CFG.</p>
                    </div>
                </div>

                <!-- Part 1.2: Using UNet to Train a Denoiser -->
                <div class="task-cluster">
                    <div class="cluster-heading">
                        <span class="task-label">1.2</span>
                        <h3>Using the UNet to Train a Denoiser</h3>
                    </div>
                    <p>Visualize noising process: z = x + σε for σ = [0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0]</p>
                    <p><strong>Implementation:</strong> Train UNet to predict clean images from noisy inputs. Add Gaussian noise ε~N(0,σ²I) to clean images, use MSELoss(predicted_clean, original_clean).</p>
                    <div class="media-row">
                        <figure>
                            <img src="src/img/partb_part_1.2:_using_the_unet_to_train_a_deno_1.png" alt="Noise levels sweep" />
                            <figcaption>Noise levels σ sweep</figcaption>
                        </figure>
                    </div>
                </div>

                <!-- Part 1.2.1: Training -->
                <div class="task-cluster">
                    <div class="cluster-heading">
                        <span class="task-label">1.2.1</span>
                        <h3>Training</h3>
                    </div>
                    <p><strong>Setup:</strong> D=128, batch=256, lr=1e-4, epochs=5, σ=0.5</p>
                    <div class="media-row">
                        <figure>
                            <img src="src/img/partb_part_1.2.1:_training_1.png" alt="Training curve" />
                            <figcaption>Training loss curve</figcaption>
                        </figure>
                        <figure>
                            <img src="src/img/partb_part_1.2.1:_training_2.png" alt="Training curve zoom" />
                            <figcaption>Loss (mid-epoch)</figcaption>
                        </figure>
                        <figure>
                            <img src="src/img/partb_part_1.2.1:_training_3.png" alt="Training curve later" />
                            <figcaption>Loss (later iterations)</figcaption>
                        </figure>
                    </div>
                </div>

                <!-- Part 1.2.2: Out-of-Distribution Testing -->
                <div class="task-cluster">
                    <div class="cluster-heading">
                        <span class="task-label">1.2.2</span>
                        <h3>Out-of-Distribution Testing</h3>
                    </div>
                    <p>Test denoiser on different σ values (trained on σ=0.5 only). From top to bottom: σ = 0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0</p>
                    <p><strong>Implementation:</strong> Generate noisy_images = test_images + torch.randn_like(test_images) * sigma_val for each σ, then run model(noisy_images) to test generalization.</p>
                    <div class="media-row">
                        <figure>
                            <img src="src/img/partb_part_1.2.2:_out-of-distribution_testing_1.png" alt="OOD sigma tests" />
                            <figcaption>OOD σ test results (rows: σ = 0.0 → 1.0)</figcaption>
                        </figure>
                    </div>
                </div>

                <!-- Part 1.2.3: Denoising Pure Noise -->
                <div class="task-cluster">
                    <div class="cluster-heading">
                        <span class="task-label">1.2.3</span>
                        <h3>Denoising Pure Noise</h3>
                    </div>
                    <p><strong>Result:</strong> Outputs blurry average of all digits (0-9). MSE loss learns the centroid—proves we need iterative denoising for generation!</p>
                    <p><strong>Implementation:</strong> Feed pure noise torch.randn_like(images) as input with clean MNIST digits as targets. Model learns to output mean of all training images since input contains no information.</p>
                    <div class="media-row">
                        <figure>
                            <img src="src/img/partb_part_1.2.3_denoising_pure_noise_1.png" alt="Pure noise denoising epochs" />
                            <figcaption>Epoch checkpoints</figcaption>
                        </figure>
                        <figure>
                            <img src="src/img/partb_part_1.2.3_denoising_pure_noise_2.png" alt="Pure noise comparison" />
                            <figcaption>Epoch 1 vs 5</figcaption>
                        </figure>
                        <figure>
                            <img src="src/img/partb_part_1.2.3_denoising_pure_noise_3.png" alt="Pure noise samples" />
                            <figcaption>Samples</figcaption>
                        </figure>
                    </div>
                </div>

                <!-- Part 2.1: Adding Time Conditioning -->
                <div class="task-cluster">
                    <div class="cluster-heading">
                        <span class="task-label">2.1</span>
                        <h3>Adding Time Conditioning to UNet</h3>
                    </div>
                    <p>Flow matching: x_t = (1-t)x_0 + tx_1, learn u(x_t,t) = x_1 - x_0. Inject t via FCBlock modulation.</p>
                    <p><strong>Implementation:</strong> Add two FCBlock modules that modulate features at bottleneck and decoder. Time scalar t∈[0,1] reshaped to (N,1) produces modulation weights: x_unflat = unflatten(x_fc * t1) and x_dec2 = decoder(x_dec3 * t2).</p>
                </div>

                <!-- Part 2.2: Training the Time-Conditioned UNet -->
                <div class="task-cluster">
                    <div class="cluster-heading">
                        <span class="task-label">2.2</span>
                        <h3>Training the Time-Conditioned UNet</h3>
                    </div>
                    <p><strong>Setup:</strong> D=64, batch=64, lr=1e-2, epochs=10, exponential LR decay γ=0.1^(1/10)</p>
                    <p><strong>Implementation:</strong> Compute flow matching loss using x_t = (1-t)*x_0 + t*x_1 where x_0~N(0,I) is noise, x_1 is clean image, t~Uniform(0,1). Model predicts flow vector, loss is MSELoss(predicted_flow, x_1 - x_0).</p>
                    <div class="media-row">
                        <figure>
                            <img src="src/img/partb_part_2.2:_training_the_time-conditioned__1.png" alt="Time-conditioned training" />
                            <figcaption>Training loss</figcaption>
                        </figure>
                    </div>
                </div>

                <!-- Part 2.3: Sampling from Time-Conditioned UNet -->
                <div class="task-cluster">
                    <div class="cluster-heading">
                        <span class="task-label">2.3</span>
                        <h3>Sampling from the Time-Conditioned UNet</h3>
                    </div>
                    <p>Euler method sampling with 50 timesteps</p>
                    <p><strong>Implementation:</strong> Start from x_t = randn() at t=0. For each timestep i, compute t = i/num_ts, predict flow u = unet(x_t, t), update x_t = x_t + u * dt with dt = 1.0/num_ts.</p>
                    <div class="media-row">
                        <figure>
                            <img src="src/img/partb_part_2.3:_sampling_from_the_time-conditi_1.png" alt="Samples overview" />
                            <figcaption>Sample overview</figcaption>
                        </figure>
                        <figure>
                            <img src="src/img/partb_part_2.3:_sampling_from_the_time-conditi_2.png" alt="Epoch 1" />
                            <figcaption>Epoch 1</figcaption>
                        </figure>
                        <figure>
                            <img src="src/img/partb_part_2.3:_sampling_from_the_time-conditi_3.png" alt="Epoch 5" />
                            <figcaption>Epoch 5</figcaption>
                        </figure>
                        <figure>
                            <img src="src/img/partb_part_2.3:_sampling_from_the_time-conditi_4.png" alt="Epoch 10" />
                            <figcaption>Epoch 10</figcaption>
                        </figure>
                    </div>
                </div>

                <!-- Part 2.4: Adding Class Conditioning -->
                <div class="task-cluster">
                    <div class="cluster-heading">
                        <span class="task-label">2.4</span>
                        <h3>Adding Class-Conditioning to UNet</h3>
                    </div>
                    <p>One-hot class vectors (0-9) with 10% dropout for CFG training. Modulation: unflatten = c1*unflatten + t1</p>
                    <p><strong>Implementation:</strong> Create one-hot vectors via F.one_hot(c, 10).float(). Implement dropout with mask = (torch.rand(batch_size) > 0.1).float(), then c_one_hot = c_one_hot * mask. Process through fc1_c and fc2_c FCBlocks.</p>
                </div>

                <!-- Part 2.5: Training Class-Conditioned UNet -->
                <div class="task-cluster">
                    <div class="cluster-heading">
                        <span class="task-label">2.5</span>
                        <h3>Training the Class-Conditioned UNet</h3>
                    </div>
                    <p><strong>Setup:</strong> Same as 2.2 but with class conditioning and p_uncond=0.1</p>
                    <p><strong>Implementation:</strong> Integrate class modulation with time modulation: x_unflat = unflatten(c1*x_fc + t1) at bottleneck and x_dec2 = decoder(c2*x_dec3 + t2) at decoder. Same flow matching loss MSELoss(predicted_flow, x_1 - x_0).</p>
                    <div class="media-row">
                        <figure>
                            <img src="src/img/partb_part_2.5_training_the_class-conditioned__1.png" alt="Class-conditioned training" />
                            <figcaption>Training loss</figcaption>
                        </figure>
                    </div>
                </div>

                <!-- Part 2.6: Sampling from Class-Conditioned UNet -->
                <div class="task-cluster">
                    <div class="cluster-heading">
                        <span class="task-label">2.6</span>
                        <h3>Sampling from the Class-Conditioned UNet</h3>
                    </div>
                    <p>CFG sampling with γ=5.0. <strong>No LR scheduler:</strong> Used constant lr=5e-3, 12 epochs, gradient clipping—maintained same quality!</p>
                    <p><strong>Implementation:</strong> At each timestep, compute two forward passes: u_cond = unet(x_t, c, t, mask=ones) and u_uncond = unet(x_t, c, t, mask=zeros). Combine: u = u_uncond + 5.0 * (u_cond - u_uncond). Use in Euler integration: x_t = x_t + u * dt.</p>
                    <div class="media-row">
                        <figure>
                            <img src="src/img/partb_part_2.6:_sampling_from_the_class-condit_1.png" alt="Epochs comparison" />
                            <figcaption>Epochs 1/5/10</figcaption>
                        </figure>
                        <figure>
                            <img src="src/img/partb_part_2.6:_sampling_from_the_class-condit_2.png" alt="CFG samples" />
                            <figcaption>CFG γ=5</figcaption>
                        </figure>
                        <figure>
                            <img src="src/img/partb_part_2.6:_sampling_from_the_class-condit_3.png" alt="Per-digit grid" />
                            <figcaption>Per-digit grid</figcaption>
                        </figure>
                    </div>
                </div>

            </section>

        </main>

        <footer>
            <div class="footer-shell">
                <span>CS 180 · Project 5</span>
                <span>Song-Ze Yu · 3042011066</span>
            </div>
        </footer>
    </div>
</body>
</html>
